{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DNEST4_PATH=/home/mariska/UvA\n"
     ]
    }
   ],
   "source": [
    "%env DNEST4_PATH=/home/mariska/UvA\n",
    "# \"hardcoded\" DNEST path in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "import time as tsys\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import dnest4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_main(filename, dnest_dir = \"./\"):\n",
    "    '''Rewrite the main.cpp to include\n",
    "    the correct path to the filename'''\n",
    "\n",
    "    mfile = open(dnest_dir+\"main.cpp\", \"r\")\n",
    "    mdata = mfile.readlines()\n",
    "    mfile.close()\n",
    "\n",
    "    ## replace filename in appropriate line:\n",
    "    mdata[-6] = '\\tData::get_instance().load(\"%s\");\\n'%filename\n",
    "\n",
    "    mfile.close()\n",
    "\n",
    "    mwrite_file = open(dnest_dir+\"main.cpp.tmp\", \"w\")\n",
    "\n",
    "    for l in mdata:\n",
    "        mwrite_file.write(l)\n",
    "\n",
    "    mwrite_file.close()\n",
    "\n",
    "    shutil.move(dnest_dir+\"main.cpp.tmp\", dnest_dir+\"main.cpp\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_options(nlevels=200, dnest_dir=\"./\"):\n",
    "\n",
    "    mfile = open(dnest_dir+\"OPTIONS\", \"r\")\n",
    "    mdata = mfile.readlines()\n",
    "    mfile.close()\n",
    "    \n",
    "    mdata[-4] = '%i\\t# maximum number of levels\\n'%nlevels\n",
    "\n",
    "    mwrite_file = open(dnest_dir+\"OPTIONS.tmp\", \"w\")\n",
    "\n",
    "    for l in mdata:\n",
    "        mwrite_file.write(l)\n",
    "\n",
    "    mwrite_file.close()\n",
    "\n",
    "    shutil.move(dnest_dir+\"OPTIONS.tmp\", dnest_dir+\"OPTIONS\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remake_model(dnest_dir=\"./\"):\n",
    "    ''' Runs make '''\n",
    "    tstart = tsys.process_time() # changed from clock to process_time\n",
    "    subprocess.call([\"make\", \"-C\", dnest_dir])\n",
    "    tsys.sleep(15)\n",
    "    tend = tsys.process_time() # changed from clock to process_time\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_burst(filename, dnest_dir = \"./\", levelfilename=None, nsims=100):\n",
    "    '''' Automatically runs the DNest4 for the given filename without having\n",
    "    to put the correct commands in the command line. Also finds the correct \n",
    "    amount of levels by running DNest4 twice. \n",
    "\n",
    "    Parameters:\n",
    "    filename: the entire path to the file\n",
    "    nsims: minimum amount of samples you want\n",
    "    '''\n",
    "\n",
    "    ### first run: set levels to 200\n",
    "    # automatically runs the functions above\n",
    "    print(\"Rewriting DNest run file (main.cpp)\")\n",
    "    rewrite_main(filename, dnest_dir)\n",
    "    rewrite_options(nlevels=200, dnest_dir=dnest_dir) # OVERWRITE OPTIONS FILE: deletes one line and adds and extra levels line\n",
    "    remake_model(dnest_dir)\n",
    "\n",
    "    # splits up the path to the file into the directory and the filename\n",
    "    fdir = filename.split(\"/\")\n",
    "    fname = fdir[-1]\n",
    "    fdir = filename[:-len(fname)]\n",
    "    print(\"directory: %s\" %fdir)\n",
    "    print(\"filename: %s\" %fname)\n",
    "\n",
    "    fsplit = fname.split(\"_\")\n",
    "    froot = \"%s%s_%s\" %(fdir, fsplit[0], fsplit[1][:-4]) ### used to be: \"%s/%s_%s\"\n",
    "    print(\"froot: \" + str(froot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory: data/\n",
      "filename: gauss_test.dat\n",
      "fsplit test\n",
      "froot: data/gauss_test\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/gauss_test.dat\"\n",
    "\n",
    "# splits up the path to the file into the directory and the filename\n",
    "fdir = filename.split(\"/\")\n",
    "fname = fdir[-1]\n",
    "fdir = filename[:-len(fname)]\n",
    "print(\"directory: %s\" %fdir)\n",
    "print(\"filename: %s\" %fname)\n",
    "\n",
    "fsplit = fname.split(\"_\")\n",
    "print('fsplit', fsplit[1][:-4])\n",
    "froot = \"%s%s_%s\" %(fdir, fsplit[0], fsplit[1][:-4]) ### used to be: \"%s/%s_%s\"\n",
    "print(\"froot: \" + str(froot))\n",
    "\n",
    "# rewrite_main(filename, dnest_dir=\"./\")\n",
    "# rewrite_options(nlevels=200, dnest_dir=\"./\")\n",
    "# remake_model(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory: data/\n",
      "filename: B3_Jan14_test.dat\n",
      "fsplit Jan14\n",
      "froot: data/B3_Jan14/B3_Jan14\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/B3_Jan14_test.dat\"\n",
    "\n",
    "# splits up the path to the file into the directory and the filename\n",
    "fdir = filename.split(\"/\")\n",
    "fname = fdir[-1]\n",
    "fdir = filename[:-len(fname)]\n",
    "print(\"directory: %s\" %fdir)\n",
    "print(\"filename: %s\" %fname)\n",
    "\n",
    "fsplit = fname.split(\"_\")\n",
    "print('fsplit', fsplit[1])\n",
    "froot = \"%s%s_%s/%s_%s\" %(fdir, fsplit[0], fsplit[1], fsplit[0], fsplit[1]) # used to be: %s/%s_%s\" and fsplit[1]: implemented to get rid of .dat in filename\n",
    "print(\"froot: \" + str(froot))\n",
    "\n",
    "# fsplit = filename.split(\"_\")\n",
    "# froot = \"%s%s_%s\" %(fdir, fsplit[0], fsplit[1][:-4]) ### used to be: \"%s/%s_%s\"\n",
    "#froot = \"%s_%s\" %(fsplit[0], fsplit[1][-4])\n",
    "# print(\"froot: \" + str(froot))\n",
    "\n",
    "\n",
    "# /home/mariska/UvA/magnetron2/data/gauss_._sample.txt\n",
    "# /home/mariska/UvA/magnetron2/data/gauss_test/gauss_test_sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_new(temperature=1., numResampleLogX=1, plot=False, save_posterior=False):\n",
    "\n",
    "    cut = 0\n",
    "\n",
    "    try:\n",
    "        levels = np.atleast_2d(np.loadtxt(\"levels.txt\"))\n",
    "        sample_info = np.atleast_2d(np.loadtxt(\"sample_info.txt\"))\n",
    "        sample = np.atleast_2d(np.loadtxt(\"csample.txt\"))\n",
    "    except IOError:\n",
    "        return None, None\n",
    "\n",
    "    sample = sample[int(cut*sample.shape[0]):, :]\n",
    "    sample_info = sample_info[int(cut*sample_info.shape[0]):, :]\n",
    "   \n",
    "    if sample.shape[0] != sample_info.shape[0]:\n",
    "        print('# Size mismatch. Truncating...')\n",
    "        lowest = np.min([sample.shape[0], sample_info.shape[0]])\n",
    "        sample = sample[0:lowest, :]\n",
    "        sample_info = sample_info[0:lowest, :]\n",
    "\n",
    "    # Convert to lists of tuples\n",
    "    logl_levels = [(levels[i,1], levels[i, 2]) for i in range(0, levels.shape[0])] # logl, tiebreaker\n",
    "    logl_samples = [(sample_info[i, 1], sample_info[i, 2], i) for i in range(0, sample.shape[0])] # logl, tiebreaker, id\n",
    "    logx_samples = np.zeros((sample_info.shape[0], numResampleLogX))\n",
    "    logp_samples = np.zeros((sample_info.shape[0], numResampleLogX))\n",
    "    logP_samples = np.zeros((sample_info.shape[0], numResampleLogX))\n",
    "    P_samples = np.zeros((sample_info.shape[0], numResampleLogX))\n",
    "    logz_estimates = np.zeros((numResampleLogX, 1))\n",
    "    H_estimates = np.zeros((numResampleLogX, 1))\n",
    "\n",
    "    # Find sandwiching level for each sample\n",
    "    sandwich = sample_info[:,0].copy().astype('int')\n",
    "    for i in range(0, sample.shape[0]):\n",
    "        while sandwich[i] < levels.shape[0]-1 and logl_samples[i] > logl_levels[sandwich[i] + 1]:\n",
    "            sandwich[i] += 1\n",
    "\n",
    "    for z in range(0, numResampleLogX):\n",
    "        # For each level\n",
    "        for i in range(0, levels.shape[0]):\n",
    "            # Find the samples sandwiched by this level\n",
    "            which = np.nonzero(sandwich == i)[0]\n",
    "            logl_samples_thisLevel = [] # (logl, tieBreaker, ID)\n",
    "            for j in range(0, len(which)):\n",
    "                logl_samples_thisLevel.append(copy.deepcopy(logl_samples[which[j]]))\n",
    "            logl_samples_thisLevel = sorted(logl_samples_thisLevel)\n",
    "            N = len(logl_samples_thisLevel)\n",
    "\n",
    "            # Generate intermediate logx values\n",
    "            logx_max = levels[i, 0]\n",
    "            if i == levels.shape[0]-1:\n",
    "                logx_min = -1E300\n",
    "            else:\n",
    "                logx_min = levels[i+1, 0]\n",
    "            Umin = np.exp(logx_min - logx_max)\n",
    "\n",
    "            if N == 0 or numResampleLogX > 1:\n",
    "                U = Umin + (1. - Umin)*np.random.rand(len(which))\n",
    "            else:\n",
    "                U = Umin + (1. - Umin)*np.linspace(1./(N+1), 1. - 1./(N+1), N)\n",
    "            logx_samples_thisLevel = np.sort(logx_max + np.log(U))[::-1]\n",
    "\n",
    "            for j in range(0, which.size):\n",
    "                logx_samples[logl_samples_thisLevel[j][2]][z] = logx_samples_thisLevel[j]\n",
    "\n",
    "                if j != which.size - 1:\n",
    "                    left = logx_samples_thisLevel[j+1]\n",
    "                elif i == levels.shape[0]-1:\n",
    "                    left = -1E300\n",
    "                else:\n",
    "                    left = levels[i+1][0]\n",
    "\n",
    "                if j != 0:\n",
    "                    right = logx_samples_thisLevel[j-1]\n",
    "                else:\n",
    "                    right = levels[i][0]\n",
    "\n",
    "                logp_samples[logl_samples_thisLevel[j][2]][z] = np.log(0.5) + logdiffexp(right, left)\n",
    "\n",
    "        logl = sample_info[:,1]/temperature\n",
    "\n",
    "        logp_samples[:,z] = logp_samples[:,z] - logsumexp(logp_samples[:,z])\n",
    "        logP_samples[:,z] = logp_samples[:,z] + logl\n",
    "        logz_estimates[z] = logsumexp(logP_samples[:,z])\n",
    "        logP_samples[:,z] -= logz_estimates[z]\n",
    "        P_samples[:,z] = np.exp(logP_samples[:,z])\n",
    "        H_estimates[z] = -logz_estimates[z] + np.sum(P_samples[:,z]*logl)\n",
    "\n",
    "    if save_posterior:\n",
    "\n",
    "        P_samples = np.mean(P_samples, 1)\n",
    "        P_samples = P_samples/np.sum(P_samples)\n",
    "        logz_estimate = np.mean(logz_estimates)\n",
    "        logz_error = np.std(logz_estimates)\n",
    "        H_estimate = np.mean(H_estimates)\n",
    "        H_error = np.std(H_estimates)\n",
    "        ESS = np.exp(-np.sum(P_samples*np.log(P_samples+1E-300)))\n",
    "\n",
    "        print(\"log(Z) = \" + str(logz_estimate) + \" +- \" + str(logz_error))\n",
    "        print(\"Information = \" + str(H_estimate) + \" +- \" + str(H_error) + \" nats.\")\n",
    "        print(\"Effective sample size = \" + str(ESS))\n",
    "\n",
    "        # Resample to uniform weight\n",
    "        N = int(ESS)\n",
    "        posterior_sample = np.zeros((N, sample.shape[1]))\n",
    "        w = P_samples\n",
    "        w = w/np.max(w)\n",
    "        np.savetxt('weights.txt', w) # Save weights\n",
    "        for i in range(0, N):\n",
    "            while True:\n",
    "                which = np.random.randint(sample.shape[0])\n",
    "                if np.random.rand() <= w[which]:\n",
    "                    break\n",
    "            posterior_sample[i,:] = sample[which,:]\n",
    "        np.savetxt(\"posterior_sample.txt\", posterior_sample)\n",
    "\n",
    "    return logx_samples, P_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weights(p_samples):\n",
    "\n",
    "    print(\"max(p_samples): %f\" %np.max(p_samples[-10:]))\n",
    "\n",
    "    ### NOTE: logx_samples runs from 0 to -120, but I'm interested in the values of p_samples near the\n",
    "    ### smallest values of X, so I need to look at the end of the list\n",
    "    if np.max(p_samples[-10:]) < 1.0e-5:\n",
    "        print(\"Returning True\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Returning False\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First run of DNest: Find number of levels\")\n",
    "## run DNest\n",
    "# run a program with modified scheduling priority of -19 (using nice).\n",
    "# Niceness values range from -20 (most favorable to the  process)  to  19  (least  favorable  to  the process).\n",
    "dnest_process = subprocess.Popen([\"nice\", \"--adjustment=-19\", \"code/main\", \"-t\", \"8\"])\n",
    "\n",
    "# endflag marks when DNest4 has to stop running \n",
    "endflag = False\n",
    "while endflag is False:\n",
    "    try:\n",
    "        # every minute the plots pop up showing the log(x), iterations, etc. \n",
    "        tsys.sleep(60)\n",
    "        logx_samples, p_samples = postprocess_new(save_posterior=False)\n",
    "        if p_samples is None:\n",
    "            endflag = False\n",
    "        else:\n",
    "            endflag = find_weights(p_samples)\n",
    "            print(\"Endflag: \" + str(endflag))\n",
    "\n",
    "    except (KeyboardInterrupt, ValueError):\n",
    "        break\n",
    "    \n",
    "# if the endflag is true print it \n",
    "print(\"endflag: \" + str(endflag))\n",
    "\n",
    "# Kill DNest4 when endflag is true: this is now the case when ...?\n",
    "dnest_process.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnest_dir=\"./\"\n",
    "# dnest_data = np.loadtxt(\"%ssample.txt\" %dnest_dir)\n",
    "dnest_data = np.loadtxt(\"/home/mariska/UvA/magnetron2/data/gauss_test.dat_sample.txt\")\n",
    "nlevels = len(dnest_data)\n",
    "\n",
    "# input function \n",
    "levelfilename = None\n",
    "\n",
    "### save levels to file\n",
    "if not levelfilename is None:\n",
    "    levelfile = open(levelfilename, \"a\")\n",
    "    levelfile.write(\"%s \\t %i \\n\" %(filename, nlevels))\n",
    "    levelfile.close()\n",
    "\n",
    "# Rerun DNest4 again, but now with the correct amount of levels calculated previously\n",
    "# For that rewrite the options file and the model(?)\n",
    "rewrite_options(nlevels=nlevels, dnest_dir=dnest_dir)\n",
    "remake_model(dnest_dir)\n",
    "\n",
    "# dnest_process = subprocess.Popen([\"nice\", \"-19\", \"./main\", \"-t\", \"8\"])\n",
    "\n",
    "# endflag = False\n",
    "# while endflag is False:\n",
    "#     try:\n",
    "#         tsys.sleep(120)\n",
    "#         logx_samples, p_samples = postprocess_new(save_posterior=True)\n",
    "#         samples = np.loadtxt(\"%sposterior_sample.txt\"%dnest_dir)\n",
    "#         print(\"samples file: %ssample.txt\" %dnest_dir)\n",
    "#         print(\"nlevels: %i\" %len(samples)) \n",
    "#         print(\"Endflag: \" + str(endflag))\n",
    "\n",
    "#         if len(samples) >= nsims and len(np.shape(samples)) > 1:\n",
    "#         #if len(samples) >= np.max([5*nlevels, 1000+nlevels]) and len(np.shape(samples)) > 1:\n",
    "#             endflag = True\n",
    "#         else:\n",
    "#             endflag = False\n",
    "#     except (KeyboardInterrupt, ValueError):\n",
    "#         break\n",
    "\n",
    "# print(\"Endflag: \" + str(endflag))\n",
    "\n",
    "# # Kill DNest4 when endflag is true: this is now the case when ...?\n",
    "# dnest_process.kill()\n",
    "    \n",
    "# logx_samples, p_samples = postprocess_new(save_posterior=True)    \n",
    "\n",
    "# fsplit = filename.split(\"_\")\n",
    "# #froot = \"%s_%s\" %(fsplit[0], fsplit[1])\n",
    "# print(\"froot: \" + str(froot))\n",
    "\n",
    "# Move all the output to ...? \n",
    "# Change the filenames so that it includes the filename(?)\n",
    "shutil.move(\"sample.txt\", \"%s_sample.txt\" %froot)\n",
    "try:\n",
    "    shutil.move(\"posterior_sample.txt\", \"%s_posterior_sample.txt\" %froot)\n",
    "    shutil.move(\"levels.txt\", \"%s_levels.txt\" %froot)\n",
    "    shutil.move(\"sample_info.txt\", \"%s_sample_info.txt\" %froot)\n",
    "    shutil.move(\"weights.txt\", \"%s_weights.txt\" %froot)\n",
    "except IOError:\n",
    "    print(\"No file posterior_sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-d DATA_DIR] [-n DNEST_DIR] [-f FILENAME]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"1c7d271a-bbf5-4d19-b3e8-099911d40a61\" --shell=9002 --transport=\"tcp\" --iopub=9004\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariska/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3377: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"Running DNest on a number of bursts\")\n",
    "\n",
    "parser.add_argument(\"-d\", \"--datadir\", action=\"store\", required=False, dest=\"data_dir\",\n",
    "                    default=\"./\", help=\"Specify directory with data files (default: current directory)\")\n",
    "parser.add_argument(\"-n\", \"--dnestdir\", action=\"store\", required=False, dest=\"dnest_dir\",\n",
    "                    default=\"./\", help=\"Specify directory with DNest model implementation \"\n",
    "                                        \"(default: current directory\")\n",
    "parser.add_argument(\"-f\", \"--filename\", action=\"store\", required=False, dest=\"filename\",\n",
    "                    default=\"test_levels.dat\", help=\"Define filename for file that saves the number of levels to use\")\n",
    "\n",
    "clargs = parser.parse_args()\n",
    "data_dir = clargs.data_dir\n",
    "dnest_dir = clargs.dnest_dir\n",
    "levelfilename = clargs.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in run_all_bursts\n",
      "['/home/mariska/UvA/magnetron2/data/gauss_test.dat', '/home/mariska/UvA/magnetron2/data/B3_Jan14_test.dat', '/home/mariska/UvA/magnetron2/data/B10_Jan14_test.dat']\n",
      "Saving levels in file /home/mariska/UvA/magnetron2/data/test_levels.dat\n",
      "Running on burst /home/mariska/UvA/magnetron2/data/gauss_test.dat\n",
      "Running on burst /home/mariska/UvA/magnetron2/data/B3_Jan14_test.dat\n",
      "Running on burst /home/mariska/UvA/magnetron2/data/B10_Jan14_test.dat\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# def run_all_bursts(data_dir=\"/home/mariska/UvA/magnetron2/data/\", dnest_dir=\"./\", levelfilename=\"test_levels.dat\"):\n",
    "data_dir=\"/home/mariska/UvA/magnetron2/data/\"\n",
    "levelfilename=\"test_levels.dat\"\n",
    "print(\"I am in run_all_bursts\")\n",
    "\n",
    "# Run all the burst by running all the files that end with .dat\n",
    "filenames = glob.glob(\"%s*_test.dat\"%data_dir)\n",
    "print(filenames)\n",
    "\n",
    "levelfilename = data_dir+levelfilename\n",
    "print(\"Saving levels in file %s\"%levelfilename)\n",
    "\n",
    "levelfile = open(levelfilename, \"w\")\n",
    "levelfile.write(\"# data filename \\t number of levels \\n\")\n",
    "levelfile.close()\n",
    "\n",
    "for f in filenames:\n",
    "    print(\"Running on burst %s\" %f)\n",
    "    # run_burst(f, dnest_dir=dnest_dir, levelfilename=levelfilename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "I am in run_all_bursts\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "data_dir=\"/home/mariska/UvA/magnetron2/data/\"\n",
    "filenames = glob.glob(\"%s*_test.dat\"%data_dir)\n",
    "\n",
    "print(filenames)\n",
    "\n",
    "run_all_bursts(data_dir=\"/home/mariska/UvA/magnetron2/data\", dnest_dir=\"./\", levelfilename=\"test_levels.dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a24673b3396adf39e3027783375ad567eea8487312628d16a9beb5384620a90a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
